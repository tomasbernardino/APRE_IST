{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "RANDOM_STATE = 0\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(data = data.data, columns = data.feature_names)\n",
    "\n",
    "\n",
    "X = scaler.fit_transform(data.data)\n",
    "y = data.target\n",
    "\n",
    "df_scaled = pd.DataFrame(data = X, columns = data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lr_model = LogisticRegression(max_iter = 1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "lr_model.predict(X_test)\n",
    "\n",
    "print(\"Model Accuracy:\", lr_model.score(X_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cluster_range = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35]\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in cluster_range:\n",
    "  gmm = GaussianMixture(n_components=k, random_state = RANDOM_STATE)\n",
    "\n",
    "  cluster_labels = gmm.fit_predict(X_train)\n",
    "  score = silhouette_score(X_train, cluster_labels)\n",
    "  silhouette_scores.append(score)\n",
    "\n",
    "\n",
    "optimal_k = cluster_range[np.argmax(silhouette_scores)]\n",
    "optimal_k, silhouette_scores\n",
    "\n",
    "print(\"Optimal K value:\", optimal_k)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cluster_range, silhouette_scores, marker='o')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.xticks(range(1, max(cluster_range)+1))\n",
    "plt.title('Silhouette Score vs. Number of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we analyze the silhouette scores across the possible values of k, we observe a sharp decrease when transitioning from k=3 to k=4 clusters. Beyond this, there is a gradual decline from k=4 to k=10. After k=10, the silhouette scores decline at a lower pace.\n",
    "\n",
    "From this analysis we can conclude that the number of clusters is inversely correlated with the quality of clustering, since higher k's lead to lower silhouette scores. Specifically, the noticeable drop in silhouette scores from 3 to 4 clusters indicates a significant reduction in clustering quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.\n",
    "\n",
    "test_probas = []\n",
    "\n",
    "for k in cluster_range:\n",
    "  gmm = GaussianMixture(n_components=k,random_state = RANDOM_STATE)\n",
    "  cluster_labels = gmm.fit_predict(X_train)\n",
    "  test_proba = gmm.predict_proba(X_test)\n",
    "  test_probas.append(test_proba)\n",
    "  \n",
    "assigned_cluster = []\n",
    "for i in range(len(test_probas)):\n",
    "  assigned_cluster_k = []\n",
    "  for j in range(len(test_probas[i])):\n",
    "    assigned_cluster_k.append(int(np.argmax(test_probas[i][j])))\n",
    "\n",
    "  assigned_cluster.append(assigned_cluster_k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "lr_k_clusters_acc = []\n",
    "for k in range(len(cluster_range)):\n",
    "  lr_k_cluster = LogisticRegression(random_state = RANDOM_STATE).fit(test_probas[k], y_test)\n",
    "  y_pred = lr_k_cluster.predict(test_probas[k])\n",
    "  lr_k_clusters_acc.append(lr_k_cluster.score(test_probas[k], y_test))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cluster_range, lr_k_clusters_acc, marker='o')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(range(1, max(cluster_range)+1))\n",
    "plt.title('Accuracy vs. Number of Clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graph, we can conclude that the optimal value for\n",
    "k is 9, with an accuracy of around 0.94. This shows that the optimal \n",
    "k value in this case is not 2, possibly because having more clusters makes it possible to capture more important information than with just two clusters. Additionally, the sharp decrease noticeable in the Silhouette Score graph does not appear in the accuracy graph until the number of clusters exceeds 10.\n",
    "\n",
    "In conclusion, there does not seem to be any correlation between the cluster evaluation values and the accuracy values when comparing them for the same number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=RANDOM_STATE)\n",
    "gmm.fit(X_train)\n",
    "\n",
    "centers = gmm.means_\n",
    "covariances = gmm.covariances_\n",
    "cov_matrixes = covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# RBF activation function\n",
    "def rbf_activation(X, center, cov_matrix):\n",
    "\n",
    "    diff = X - center\n",
    "    inv_cov = np.linalg.inv(cov_matrix)\n",
    "    exponent = -0.5 * np.sum(diff @ inv_cov * diff, axis=1)\n",
    "    return np.exp(exponent)\n",
    "\n",
    "def forward_propagation(X, centers, cov_matrixes, weights):\n",
    "\n",
    "    rbf_outputs = np.array([rbf_activation(X, center, cov_matrix) for (center,cov_matrix) in zip(centers, cov_matrixes)])  # (k, n)\n",
    "    rbf_outputs = rbf_outputs.T \n",
    "\n",
    "    outputs = sigmoid(np.dot(rbf_outputs, weights))\n",
    "\n",
    "    return rbf_outputs, outputs\n",
    "\n",
    "# Training function\n",
    "\n",
    "def train_rbf_network(X, T, centers, cov_matrixes, weights, learning_rate, epochs):\n",
    "    T = T.reshape(-1, 1) # reshapes the target vector `T` into a column vector with dimensions (n, 1)\n",
    "    for epoch in range(epochs):\n",
    "        rbf_Phi, O = forward_propagation(X, centers, cov_matrixes, weights)\n",
    "\n",
    "        errors = T - O\n",
    "        # Update weights\n",
    "        weights += learning_rate * np.dot(rbf_Phi.T,errors)\n",
    "\n",
    "    return weights\n",
    "\n",
    "def predict(X, centers, cov_matrixes, weights):\n",
    "\n",
    "    _, O = forward_propagation(X, centers, cov_matrixes, weights)\n",
    "\n",
    "    return (O >= 0.5).astype(int)  # Binary classification (0 or 1),\n",
    "                                  # if over 0.5 than there's more chance of being 1\n",
    "\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "epochs_possibilities = [10, 50, 100, 200, 300, 400, 500]\n",
    "\n",
    "train_accuracies = {lr: [] for lr in learning_rate}\n",
    "test_accuracies = {lr: [] for lr in learning_rate}\n",
    "\n",
    "\n",
    "for epochs in epochs_possibilities:\n",
    "    for lr in learning_rate:\n",
    "        weights = np.full((len(centers), 1), 0.1)  # Initialize the weights for output layer (binary classification)\n",
    "        # Train the network\n",
    "        trained_weights = train_rbf_network(X_train, y_train, centers, cov_matrixes, weights, lr, epochs)\n",
    "\n",
    "        # Predict and evaluate accuracy for training set\n",
    "        y_train_pred = predict(X_train, centers, cov_matrixes, trained_weights)\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        train_accuracies[lr].append(train_acc)\n",
    "\n",
    "        y_test_pred = predict(X_test, centers, cov_matrixes, trained_weights)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        test_accuracies[lr].append(test_acc)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "lr_colors = {\n",
    "    0.001: 'blue',\n",
    "    0.01: 'green',\n",
    "    0.1: 'red'\n",
    "}\n",
    "\n",
    "for lr in learning_rate:\n",
    "    plt.plot(epochs_possibilities, train_accuracies[lr], label=f'Training Accuracy (lr={lr})',color=lr_colors[lr])\n",
    "\n",
    "\n",
    "for lr in learning_rate:\n",
    "    plt.plot(epochs_possibilities, test_accuracies[lr], linestyle='--', label=f'Testing Accuracy (lr={lr})', color=lr_colors[lr])\n",
    "\n",
    "plt.title('Training and Testing Accuracy vs. Epochs for Different Learning Rates')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"target\")\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix with Target Variable')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
